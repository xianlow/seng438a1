>   **SENG 438 - Software Testing, Reliability, and Quality**

**Lab. Report \#1 – Introduction to Testing and Defect Tracking**

| Group: 1      |
|-----------------|
| Xian Wei Low    30113016           |   
| Akashdeep Singh 30128444           |   
| Abdul Moeiz 30113088               |   
| Cale Morash 30066719               |   


**Table of Contents**

(When you finish writing, update the following list using right click, then
“Update Field”)

[1 Introduction	1](#_Toc439194677)

[2 High-level description of the exploratory testing plan	1](#_Toc439194678)

[3 Comparison of exploratory and manual functional testing	1](#_Toc439194679)

[4 Notes and discussion of the peer reviews of defect reports	1](#_Toc439194680)

[5 How the pair testing was managed and team work/effort was
divided	1](#_Toc439194681)

[6 Difficulties encountered, challenges overcome, and lessons
learned	1](#_Toc439194682)

[7 Comments/feedback on the lab and lab document itself	1](#_Toc439194683)

# Introduction

As a team of developers, we have tested many programs before. This will be the first time we are dedicately only testing a program instead writing a program and testing midway. This means that we were checking for bugs using only exploratory testing and manual functm. ional testing. Now, we will be learning how to test a program in a organzized manner which allows us to find more bugs that comes with our program. To achieve this, we will be using different testing methods such as Manual Scripted Testing and regression testing. Not only are we able to find more, we will be able to track down the steps to reproduce a bug. This will decrease the amount time needed to go through the code and find the bug. 

# High-level description of the exploratory testing plan

In this lab, we will be testing using a exploratory test plan at at the start. Exploratory testing is what most of us developers have done even if wem do not have a plan. Going forward, we will have to write test plans to make the testing process as organized as possible. The very first step will be to write out a formulated plan to test the program. We will be writing a plan to use explaratory testing to its utmost efficiency. For this, we will tasking each pair to test out certain functions such as transfering. From there, we will look at the test cases marked for that situations and try to play around with the GUI to see what happens when we do not follow the steps given to us in the lab requirements in Appendix C. Of course we will be writing down our steps we did to reach a certain state. When we discover a bug in this stage, we will write down a report in Jira. These will not be marked with MFT but will marked with ver 1.0. IF they are fixed with ver 1.1, we will marked it down as fixed in ver 1.1 and also be marked as done.

# Comparison of exploratory and manual functional testing

When testing using exploratory methods, we are mainly testing that are not the generic steps that users may follow. This ensures if a user presses or inputs a incorrect value, no bugs may occur. Though this method will not catch all bugs, it is a way to test just in case any issues occur that was not stated in any test case. Unfortunately, we would have to create our own test plan on how to go forward with exploratory testing since it can get messy if done without a plan. That is where manual functional testing will come to play. For this we will be using the test cases provided to us in the lab document. This will provide us the use cases to test out and the relative steps to achieve our desired outcome. If we do not get said outcome, we will write document it in our defect report. 

# Notes and discussion of the peer reviews of defect reports

As required from the lab document, we splitted into groups of 2 pairs:
- Pair1: Xian and Akashdeep
- Pair2: Abdul and Cale

Each of the pairs performed an exploratory tests for approximately 20 to 30 minutes, to familiarize with the system and spot any defects throughout the process. Whenever a defect or bug was found a member would create and issue in Jira and it gets cross-checked by the corresponding partner. This ensured defects were re-checked and verified in a objective manner.

With the similar collaboration style, __Pair 1__ handled the first 20 SUIT test cases and the __Pair 2__ handles the remaining latter 20. Both member of each pair would test the same test case but with different scenarios to have a broader range and coverage of testing. This allowed us to find particular bugs, such as __system crash when card input is 3__, that would have been harder to find alone. Again, each issue added to Jira was re-inspected by the other partner to objectively verify the existence of bugs. The manual functional testing procedure took approximatley 2 hours for __Pair 1__ and approximately 3 hours to __Pair 2__, since most of the bugs were in the latter test cases. 
Therefore, to speed up the process and boost the teamwork environment performance, __Pair 1__ continued to assist __Pair 2__ with the remaining test cases.

Finally, once the exploraratory and manual scripted testing were completed, the pairs swapped their test cases during the regression testing. __Pair 2__ handled regression testing for the first 20 test cases and __Pair 1__ for the remaining. The main purpose was again to minimize subjective opinions and ensure defects were assessed in an objective manner. Once __Pair 2__ finished the regression testing, it continued assisting __Pair 1__ with the remaining test cases left. The whole process for regression testing took approximately less than 2 hours. The major reason of the speed was that the group was already enough familiar with the application and the spotted defects from the previous version of the ATM system.

# How the pair testing was managed and team work/effort was divided 

During the exploratory phase, the main funcitonalities which are system startup/shutdown, session, withdrawal, deposit, transfer, inquiry, and invalid pin extension were split amongst the pairs. Within the pairs, one member would test one of the functionalities at length in a non scripted manner with a variety of different steps taken and inputs to find any possible defects. The other member would watch, give suggestions, and note down any defects found to later be formally entered into Jira. When satisfied, they would move on to the next functionality and the roles would be swapped. After both duos were finished this process, the entire team got together and demonstrated the defects found to eachother and entered them into Jira.

Later, during the scripted phase, the test cases were split evenly per teammate. Each team member acted as the driver for their assigned test cases while the other members watched and helped them replicate the test cases and verified the formatting of the bugs being reported. The regression phase was completed similarly, with the bugs being reported in the exploratory phase being tested on version 1.1 by the same member who reported them initially on 1.0.

# Difficulties encountered, challenges overcome, and lessons learned

One of the initial challenges was to indeed first comprehend the assignment requirements. The amount of information was very detailed and initially confusing, however reading specific portions and tying it all together allowed to get the big-picture.  The lesson learned was breaking things into pieces and combining them all allows to understand details and complex things in a simpler and easier manner.

Another issue was getting familiar with the -jar file software. Initially the applicatoin felt unclear, but after following the instructions provided and applying a few test cases from Appendix C, the overall system began to feel familiar. The lesson learned was practice and re-iteration makes an unknown application seem familiar.

Also one more issue was to indeed learn for the first time and issue tracking platform. We decided to use Jira and we all were knew to it. This meant initially there was confusing on creating issues and how to setup the proper fields and attributes. However discussing it together and looking up the documentation publicly available allowed to us to get the general overview and the right sense on how to use Jira. We also helped each other out on how to get started and later the efforts speeded up the process in tracking, viewing and understanding each other's issues. The lesson learned is publicly available resources and helping each other out can help speed things up in leaning.

# Comments/feedback on the lab and lab document itself

The lab document (i.e. the assignment requirements description) was indeed too much detailed as mentioned before. The main reason were not really the detailed amount of description but rather the fact that it felt disorganized. We believe that if the document had better styling (for instance indenting and/or smaller font for portion of text that was less relevant) it could have allowed to not only read faster but also comprehend in a more structured way.

We did indeed appreciate the well defined steps and procedure on getting familiar with the ATM -jar application. That was very helpful. However, again styling could have been better, as it was cluttering the document and document requires plenty amount of scrolling to jump between portion of texts.

Another positive thing of the lab assignment is the use of a github classroom. It made it very easy for us to get started and to ensure everyone was on the same repository. The process felt smoother and more synchronized alongside with use of Jira.
